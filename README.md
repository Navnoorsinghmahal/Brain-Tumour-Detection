# Brain-Tumour-Detection

# Brain Tumor Detection using Convolutional Neural Networks

This project involves building and training a Convolutional Neural Network (CNN) for brain tumor detection. The CNN is trained to classify images into two categories: "tumor" and "no tumor". The project includes data augmentation, model training, and evaluation.

## Project Structure

- `data_augmentation.py`: Script for augmenting the dataset (to be run before training the model).
- `train_model.py`: Script for training the CNN model.
- `view_model.py`: Script for evaluating and visualizing the model.
- `models/`: Directory where the trained models are saved.
- `logs/`: Directory for TensorBoard logs.
- `augmented_data/`: Directory containing the augmented dataset (generated by `data_augmentation.py`).
- `loss_plot.png`: Plot of the training and validation loss.
- `accuracy_plot.png`: Plot of the training and validation accuracy.

## Prerequisites

Make sure you have the following Python packages installed:
- TensorFlow
- scikit-learn
- Pillow
- OpenCV
- NumPy
- Matplotlib

You can install these packages using pip:
```bash
pip install tensorflow scikit-learn pillow opencv-python-headless numpy matplotlib
```
## Setup and Running the Project

1. **Run Data Augmentation**

   Before training the model, you need to run the data augmentation script to prepare the dataset. This script will generate augmented images for training.

   ```bash
   python data_augmentation.py
    ```
2. **Train the Model
After data augmentation, you can train the CNN model using the train_model.py script. This script will build, compile, and train the model, and save it to the models/ directory.

```bash
python train_model.py
```

3. **Evaluate the Model
Once the model is trained, you can use the view_model.py script to evaluate the model's performance on the test set. This script will also save plots of training/validation metrics and images of misclassified samples.

```bash
python view_model.py
```

## Notes

- **Data Augmentation**: Ensure you run the `data_augmentation.py` script before training the model to generate the necessary augmented dataset. The augmented images are crucial for improving the model's performance and generalization.

- **Model Checkpoints**: The `train_model.py` script saves the best model during training based on validation accuracy. The saved models are stored in the `models/` directory with filenames indicating the epoch and validation accuracy.

- **TensorBoard Logs**: Training logs for TensorBoard are stored in the `logs/` directory. You can use TensorBoard to visualize training metrics and monitor the training process.

- **Evaluation**: After training, use the `view_model.py` script to evaluate the model's performance on the test set. It also generates plots of training and validation metrics and saves images of misclassified samples for further analysis.

- **Environment**: Ensure you have the correct Python environment and dependencies installed as specified in the prerequisites. It's recommended to use a virtual environment to manage dependencies.

- **File Paths**: Update file paths in the scripts if necessary, especially when running the scripts on different machines or environments.

- **Script Execution Order**: Follow the order of script execution:
  1. `data_augmentation.py` to prepare the dataset.
  2. `train_model.py` to train and save the model.
  3. `view_model.py` to evaluate and visualize the model's performance.

     
